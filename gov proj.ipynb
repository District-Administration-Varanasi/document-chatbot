{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9449a654",
   "metadata": {},
   "source": [
    "# The Approach that I will be using to solve this project\n",
    "\n",
    "##Data Collection and Integration:\n",
    "Scrape data from websites such as upvidhai.gov.in/Act.aspx and shasanadesh.up.gov.in.\n",
    "Convert PDF documents into text format for further processing.\n",
    "Organize and integrate the collected data into a structured format that the chatbot can access easily.\n",
    "##Language Processing Capability:\n",
    "For English text:\n",
    "Utilize libraries like PyPDF2 or pdfplumber in Python to extract text from PDFs.\n",
    "Implement techniques like tokenization and part-of-speech tagging to process English text.\n",
    "For Hindi text:\n",
    "Use Optical Character Recognition (OCR) libraries like Tesseract OCR for extracting Hindi text from scanned PDFs.\n",
    "Preprocess the OCR output to improve accuracy (e.g., noise removal, image enhancement).\n",
    "##Natural Language Understanding (NLU):\n",
    "Implement NLU techniques such as intent classification and named entity recognition (NER) to understand user queries.\n",
    "Use pre-trained models like BERT or spaCy for NLU tasks.\n",
    "Develop algorithms to match user queries with relevant sections of the documents.\n",
    "##Content Structuring and Storage:\n",
    "Structure the extracted text into meaningful chunks based on topics or sections.\n",
    "Store the structured content in a database (e.g., SQLite, MongoDB) for efficient retrieval.\n",
    "Implement indexing for fast search and retrieval.\n",
    "##Multi-Language Support:\n",
    "Utilize translation APIs or libraries like Google Translate or Microsoft Translator for translating content between Hindi and English.\n",
    "Ensure that translated content retains accuracy and context.\n",
    "##LLM Integration and Training:\n",
    "Integrate a Language Model (LM) like GPT-3 for generating cohesive answers.\n",
    "Fine-tune the LM on relevant datasets to align with the style of government documents and user queries.\n",
    "Implement mechanisms to control the generation of answers to ensure relevance and accuracy.\n",
    "##User Interface:\n",
    "Develop a user-friendly interface for the chatbot.\n",
    "Provide options for users to input queries and select language preferences.\n",
    "Design the interface to display results in a clear and understandable format.\n",
    "##Testing and Evaluation:\n",
    "Test the chatbot thoroughly using various test cases and edge cases.\n",
    "Evaluate the accuracy of the bot's responses and its ability to retrieve relevant information.\n",
    "Collect feedback from users and iterate on improvements.\n",
    "##Deployment:\n",
    "Deploy the chatbot on a suitable platform such as a web server or cloud service.\n",
    "Ensure scalability and reliability of the deployed system.\n",
    "Monitoring and Maintenance:\n",
    "Monitor the performance of the chatbot regularly.\n",
    "Update the chatbot's knowledge base with new documents or changes in existing documents.\n",
    "Address any issues or bugs that arise in the system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c9b1ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pytesseract\n",
    "from pdf2image import convert_from_path\n",
    "import spacy\n",
    "from spacy.lang.hi import Hindi\n",
    "from spacy.lang.en import English\n",
    "from googletrans import Translator\n",
    "import sqlite3\n",
    "from transformers import pipeline\n",
    "\n",
    "class GovernmentDocumentChatbot:\n",
    "    def __init__(self):\n",
    "        self.english_nlp = English()\n",
    "        self.hindi_nlp = Hindi()\n",
    "        self.translator = Translator()\n",
    "        self.db_connection = sqlite3.connect('government_data.db')\n",
    "        self.lm_pipeline = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "    def extract_text_from_pdf(self, file_path):\n",
    "        pages = convert_from_path(file_path, 350)  # Convert PDF to images\n",
    "        text = \"\"\n",
    "        for page in pages:\n",
    "            text += pytesseract.image_to_string(page, lang='eng+hin')  # OCR\n",
    "        return text\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        # Add preprocessing steps as needed\n",
    "        return text\n",
    "\n",
    "    def store_text_in_database(self, text):\n",
    "        cursor = self.db_connection.cursor()\n",
    "        # Create table if not exists\n",
    "        cursor.execute('''CREATE TABLE IF NOT EXISTS government_data (id INTEGER PRIMARY KEY, text TEXT)''')\n",
    "        cursor.execute('''INSERT INTO government_data (text) VALUES (?)''', (text,))\n",
    "        self.db_connection.commit()\n",
    "\n",
    "    def translate_text(self, text, target_lang='en'):\n",
    "        translation = self.translator.translate(text, dest=target_lang)\n",
    "        return translation.text\n",
    "\n",
    "    def retrieve_text_from_database(self, query):\n",
    "        cursor = self.db_connection.cursor()\n",
    "        cursor.execute('''SELECT text FROM government_data WHERE text LIKE ?''', ('%' + query + '%',))\n",
    "        result = cursor.fetchall()\n",
    "        return [row[0] for row in result]\n",
    "\n",
    "    def generate_answer(self, query, documents):\n",
    "        # Use LM to generate answer\n",
    "        input_text = ' '.join(documents) + ' ' + query\n",
    "        answer = self.lm_pipeline(input_text, max_length=50, do_sample=False)[0]['generated_text']\n",
    "        return answer\n",
    "\n",
    "    def process_query(self, query, language):\n",
    "        if language == 'en':\n",
    "            query = self.preprocess_text(query)\n",
    "        elif language == 'hi':\n",
    "            query = self.translate_text(query, target_lang='en')\n",
    "        documents = self.retrieve_text_from_database(query)\n",
    "        if documents:\n",
    "            answer = self.generate_answer(query, documents)\n",
    "        else:\n",
    "            answer = \"Sorry, I couldn't find relevant information.\"\n",
    "        if language == 'hi':\n",
    "            answer = self.translate_text(answer, target_lang='hi')\n",
    "        return answer\n",
    "\n",
    "    def close_connection(self):\n",
    "        self.db_connection.close()\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot = GovernmentDocumentChatbot()\n",
    "\n",
    "    # Example of extracting text from a PDF\n",
    "    pdf_file_path = \"sample.pdf\"\n",
    "    extracted_text = chatbot.extract_text_from_pdf(pdf_file_path)\n",
    "    chatbot.store_text_in_database(extracted_text)\n",
    "\n",
    "    # Example of processing a user query\n",
    "    query = \"What is the eligibility criteria for the XYZ scheme?\"\n",
    "    language = \"en\"  # User's language preference\n",
    "    answer = chatbot.process_query(query, language)\n",
    "    print(\"Answer:\", answer)\n",
    "\n",
    "    chatbot.close_connection()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
